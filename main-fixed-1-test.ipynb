{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azure.storage.blob import BlockBlobService\nfrom pyspark            import SparkConf,    SparkContext\nfrom pyspark.sql        import SparkSession, SQLContext\nfrom pyspark.sql        import functions as f\nfrom pyspark.sql.types  import *\nimport doctest\n\nstorageAccountName = \"dvbatch\"\nstorageKey         = \"d/xdWGVlp4DYi7JCvjEuYW/OaeSBEupMpG/5SlyE7CheMA0s1rHAByjxQ3zSemgvCI70BcyDDpT5s9K1BVMO3g==\"\ncontainerName      = \"output\"\nfile               = \"fixed-width-1.txt\"\n\n# Establish connection with the blob storage account\nblobService = BlockBlobService(account_name=storageAccountName,\n                               account_key =storageKey\n                               )",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create spark session\nspark = SparkSession.builder.master(\"local\").appName(\"fixed-width\"                          )\\\n                                            .config(\"spark.some.config.option\", \"some-value\")\\\n                                            .getOrCreate()",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def remove_header(_file = file):\n    '''\n    Removes header from .txt file by filtering out the first row & returning\n    a new dataframe without header.\n    Parameters\n    ----------\n    _file : str\n        Path to the .txt file we'll be reading\n    >>> remove_header(file)\n    +----------------------------------------------------+\n    |value                                               |\n    +----------------------------------------------------+\n    | 16524  01  3930621977  TXNPUES                     |\n    |191675  01  2368183100  OUNHQEX                     |\n    |191667  01  3714468136  GHAKASC                     |\n    |191673  01  2632703881  PAHFSAP                     |\n    | 80495  01  2766389794  XDZANTV                     |\n    +----------------------------------------------------+\n    only showing top 5 rows\n    <BLANKLINE>\n    DataFrame[value: string]\n    ''' \n    # Read in fixed-width text file into DataFrame\n    df     = spark.read.text(_file)\n\n    # Remove header\n    header = df.first()[0]\n    df     = df.filter(~f.col(\"value\").contains(header))\n    df.show(5,False)\n    \n    return df\n    \ndf = remove_header(file)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+----------------------------------------------------+\n|value                                               |\n+----------------------------------------------------+\n| 16524  01  3930621977  TXNPUES                     |\n|191675  01  2368183100  OUNHQEX                     |\n|191667  01  3714468136  GHAKASC                     |\n|191673  01  2632703881  PAHFSAP                     |\n| 80495  01  2766389794  XDZANTV                     |\n+----------------------------------------------------+\nonly showing top 5 rows\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "doctest.run_docstring_examples(remove_header, globals(), verbose=True)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Finding tests in NoName\nTrying:\n    remove_header(file)\nExpecting:\n    +----------------------------------------------------+\n    |value                                               |\n    +----------------------------------------------------+\n    | 16524  01  3930621977  TXNPUES                     |\n    |191675  01  2368183100  OUNHQEX                     |\n    |191667  01  3714468136  GHAKASC                     |\n    |191673  01  2632703881  PAHFSAP                     |\n    | 80495  01  2766389794  XDZANTV                     |\n    +----------------------------------------------------+\n    only showing top 5 rows\n    <BLANKLINE>\n    DataFrame[value: string]\nok\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def sort_df(_df = df):\n    '''\n    Take the fixed width file and split into distinct columns\n    Parameters\n    ----------\n    _file : str\n        Path to the .txt file we'll be reading\n    >>> sort_df(df)\n    +------+---+-----------+-----------+\n    | Entry|Per|    Account|Description|\n    +------+---+-----------+-----------+\n    | 16524| 01| 3930621977| TXNPUES   |\n    |191675| 01| 2368183100| OUNHQEX   |\n    |191667| 01| 3714468136| GHAKASC   |\n    |191673| 01| 2632703881| PAHFSAP   |\n    | 80495| 01| 2766389794| XDZANTV   |\n    | 80507| 01| 4609266335| BWWYEZL   |\n    | 80509| 01| 1092717420| QJYPKVO   |\n    | 80497| 01| 3386366766| SOQLCMU   |\n    |191669| 01| 5905893739| FYIWNKA   |\n    |191671| 01| 2749355876|   CBMJTLP |\n    +------+---+-----------+-----------+\n    <BLANKLINE>\n    root\n     |-- Entry: string (nullable = true)\n     |-- Per: string (nullable = true)\n     |-- Account: string (nullable = true)\n     |-- Description: string (nullable = true)\n    <BLANKLINE>\n    DataFrame[Entry: string, Per: string, Account: string, Description: string]\n    '''\n    _sorted_df = _df.select(\n        _df.value.substr( 1,  6).alias('Entry'      ),\n        _df.value.substr( 8,  3).alias('Per'        ),\n        _df.value.substr(12, 11).alias('Account'    ),\n        _df.value.substr(24, 11).alias('Description'),\n    )\n    _sorted_df.show()\n    _sorted_df.printSchema()\n    \n    return _sorted_df\n\nsorted_df = sort_df(df)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+------+---+-----------+-----------+\n| Entry|Per|    Account|Description|\n+------+---+-----------+-----------+\n| 16524| 01| 3930621977| TXNPUES   |\n|191675| 01| 2368183100| OUNHQEX   |\n|191667| 01| 3714468136| GHAKASC   |\n|191673| 01| 2632703881| PAHFSAP   |\n| 80495| 01| 2766389794| XDZANTV   |\n| 80507| 01| 4609266335| BWWYEZL   |\n| 80509| 01| 1092717420| QJYPKVO   |\n| 80497| 01| 3386366766| SOQLCMU   |\n|191669| 01| 5905893739| FYIWNKA   |\n|191671| 01| 2749355876|   CBMJTLP |\n+------+---+-----------+-----------+\n\nroot\n |-- Entry: string (nullable = true)\n |-- Per: string (nullable = true)\n |-- Account: string (nullable = true)\n |-- Description: string (nullable = true)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "doctest.run_docstring_examples(sort_df, globals(), verbose=True)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Finding tests in NoName\nTrying:\n    sort_df(df)\nExpecting:\n    +------+---+-----------+-----------+\n    | Entry|Per|    Account|Description|\n    +------+---+-----------+-----------+\n    | 16524| 01| 3930621977| TXNPUES   |\n    |191675| 01| 2368183100| OUNHQEX   |\n    |191667| 01| 3714468136| GHAKASC   |\n    |191673| 01| 2632703881| PAHFSAP   |\n    | 80495| 01| 2766389794| XDZANTV   |\n    | 80507| 01| 4609266335| BWWYEZL   |\n    | 80509| 01| 1092717420| QJYPKVO   |\n    | 80497| 01| 3386366766| SOQLCMU   |\n    |191669| 01| 5905893739| FYIWNKA   |\n    |191671| 01| 2749355876|   CBMJTLP |\n    +------+---+-----------+-----------+\n    <BLANKLINE>\n    root\n     |-- Entry: string (nullable = true)\n     |-- Per: string (nullable = true)\n     |-- Account: string (nullable = true)\n     |-- Description: string (nullable = true)\n    <BLANKLINE>\n    DataFrame[Entry: string, Per: string, Account: string, Description: string]\nok\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def remove_spaces(_sorted_df = sorted_df):\n    '''\n    Remove leading spaces from all columns in dataframe\n    Parameters\n    ----------\n    _sorted_df : dataframe\n        Dataframe to be manipulated\n    >>> remove_spaces(sorted_df)\n    +------+---+----------+-----------+\n    | Entry|Per|   Account|Description|\n    +------+---+----------+-----------+\n    | 16524| 01|3930621977|    TXNPUES|\n    |191675| 01|2368183100|    OUNHQEX|\n    |191667| 01|3714468136|    GHAKASC|\n    |191673| 01|2632703881|    PAHFSAP|\n    | 80495| 01|2766389794|    XDZANTV|\n    | 80507| 01|4609266335|    BWWYEZL|\n    | 80509| 01|1092717420|    QJYPKVO|\n    | 80497| 01|3386366766|    SOQLCMU|\n    |191669| 01|5905893739|    FYIWNKA|\n    |191671| 01|2749355876|    CBMJTLP|\n    +------+---+----------+-----------+\n    <BLANKLINE>\n    DataFrame[Entry: string, Per: string, Account: string, Description: string]\n    '''\n    for colname in _sorted_df.columns:\n        _sorted_df = _sorted_df.withColumn(colname, f.trim(f.col(colname)))\n        \n    # Verify that removal of leading & trailing spaces were removed\n    _sorted_df.show()\n    \n    return _sorted_df\n    \nsorted_df = remove_spaces(sorted_df)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+------+---+----------+-----------+\n| Entry|Per|   Account|Description|\n+------+---+----------+-----------+\n| 16524| 01|3930621977|    TXNPUES|\n|191675| 01|2368183100|    OUNHQEX|\n|191667| 01|3714468136|    GHAKASC|\n|191673| 01|2632703881|    PAHFSAP|\n| 80495| 01|2766389794|    XDZANTV|\n| 80507| 01|4609266335|    BWWYEZL|\n| 80509| 01|1092717420|    QJYPKVO|\n| 80497| 01|3386366766|    SOQLCMU|\n|191669| 01|5905893739|    FYIWNKA|\n|191671| 01|2749355876|    CBMJTLP|\n+------+---+----------+-----------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "doctest.run_docstring_examples(remove_spaces, globals(), verbose=True)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Finding tests in NoName\nTrying:\n    remove_spaces(sorted_df)\nExpecting:\n    +------+---+----------+-----------+\n    | Entry|Per|   Account|Description|\n    +------+---+----------+-----------+\n    | 16524| 01|3930621977|    TXNPUES|\n    |191675| 01|2368183100|    OUNHQEX|\n    |191667| 01|3714468136|    GHAKASC|\n    |191673| 01|2632703881|    PAHFSAP|\n    | 80495| 01|2766389794|    XDZANTV|\n    | 80507| 01|4609266335|    BWWYEZL|\n    | 80509| 01|1092717420|    QJYPKVO|\n    | 80497| 01|3386366766|    SOQLCMU|\n    |191669| 01|5905893739|    FYIWNKA|\n    |191671| 01|2749355876|    CBMJTLP|\n    +------+---+----------+-----------+\n    <BLANKLINE>\n    DataFrame[Entry: string, Per: string, Account: string, Description: string]\nok\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def cast_columns(_sorted_df = sorted_df):\n    '''\n    Cast each column to specified type\n    Parameters\n    ----------\n    _sorted_df : dataframe\n        Dataframe to be manipulated\n    >>> cast_columns(sorted_df)\n    +------+---+----------+-----------+\n    | Entry|Per|   Account|Description|\n    +------+---+----------+-----------+\n    | 16524|  1|3930621977|    TXNPUES|\n    |191675|  1|2368183100|    OUNHQEX|\n    |191667|  1|3714468136|    GHAKASC|\n    |191673|  1|2632703881|    PAHFSAP|\n    | 80495|  1|2766389794|    XDZANTV|\n    | 80507|  1|4609266335|    BWWYEZL|\n    | 80509|  1|1092717420|    QJYPKVO|\n    | 80497|  1|3386366766|    SOQLCMU|\n    |191669|  1|5905893739|    FYIWNKA|\n    |191671|  1|2749355876|    CBMJTLP|\n    +------+---+----------+-----------+\n    <BLANKLINE>\n    root\n     |-- Entry: long (nullable = true)\n     |-- Per: integer (nullable = true)\n     |-- Account: long (nullable = true)\n     |-- Description: string (nullable = true)\n    <BLANKLINE>\n    DataFrame[Entry: bigint, Per: int, Account: bigint, Description: string]\n    '''\n    cast = [f.col('Entry')      .cast('long'  ),\n            f.col('Per'  )      .cast('int'   ),\n            f.col('Account')    .cast('long'  ),\n            f.col('Description').cast('string')\n           ]              \n\n    _sorted_df = _sorted_df.select(cast)\n    _sorted_df.show()\n    _sorted_df.printSchema()\n    \n    return _sorted_df\n\nsorted_df = cast_columns(sorted_df)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+------+---+----------+-----------+\n| Entry|Per|   Account|Description|\n+------+---+----------+-----------+\n| 16524|  1|3930621977|    TXNPUES|\n|191675|  1|2368183100|    OUNHQEX|\n|191667|  1|3714468136|    GHAKASC|\n|191673|  1|2632703881|    PAHFSAP|\n| 80495|  1|2766389794|    XDZANTV|\n| 80507|  1|4609266335|    BWWYEZL|\n| 80509|  1|1092717420|    QJYPKVO|\n| 80497|  1|3386366766|    SOQLCMU|\n|191669|  1|5905893739|    FYIWNKA|\n|191671|  1|2749355876|    CBMJTLP|\n+------+---+----------+-----------+\n\nroot\n |-- Entry: long (nullable = true)\n |-- Per: integer (nullable = true)\n |-- Account: long (nullable = true)\n |-- Description: string (nullable = true)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "doctest.run_docstring_examples(cast_columns, globals(), verbose=True)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Finding tests in NoName\nTrying:\n    cast_columns(sorted_df)\nExpecting:\n    +------+---+----------+-----------+\n    | Entry|Per|   Account|Description|\n    +------+---+----------+-----------+\n    | 16524|  1|3930621977|    TXNPUES|\n    |191675|  1|2368183100|    OUNHQEX|\n    |191667|  1|3714468136|    GHAKASC|\n    |191673|  1|2632703881|    PAHFSAP|\n    | 80495|  1|2766389794|    XDZANTV|\n    | 80507|  1|4609266335|    BWWYEZL|\n    | 80509|  1|1092717420|    QJYPKVO|\n    | 80497|  1|3386366766|    SOQLCMU|\n    |191669|  1|5905893739|    FYIWNKA|\n    |191671|  1|2749355876|    CBMJTLP|\n    +------+---+----------+-----------+\n    <BLANKLINE>\n    root\n     |-- Entry: long (nullable = true)\n     |-- Per: integer (nullable = true)\n     |-- Account: long (nullable = true)\n     |-- Description: string (nullable = true)\n    <BLANKLINE>\n    DataFrame[Entry: bigint, Per: int, Account: bigint, Description: string]\nok\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\ndef createTimeStamp(): \n    \"\"\"\n    Time stamp to file path to prevent saving over orignial file.\n    \"\"\"\n    from datetime import datetime\n\n    # datetime object containing current date and time\n    now = datetime.now()\n\n    # /dd-mm-YY_H:M\n    dt_string = now.strftime(\"/%d-%m-%Y_%H-%M\")    \n\n    return dt_string",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create an output folder with a timestamp to prevent overwriting files\noutput_dir   = \"output\" + createTimeStamp() \nprint(output_dir)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "output/15-05-2020_17-16\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Make directory and write files to it\nimport os\nfrom   os import path\n\ntry:\n    sorted_df.write.parquet(output_dir)\n    files_in_dir = output_dir +\"/*\"\n    \nexcept FileExistsError:\n    print(\"Path exists -- skipping\")\n    print(output_dir)\n    pass",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Print files we just saved with Spark\nimport glob\nprint(glob.glob(files_in_dir))",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['output/15-05-2020_17-16/part-00000-607454d5-5b50-469e-98c3-1a895cf59c19-c000.snappy.parquet', 'output/15-05-2020_17-16/_SUCCESS']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Write/upload files to blob storage\nfor file in glob.glob(files_in_dir):\n    print(file)\n    blobService.create_blob_from_path(containerName, file, file)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "output/15-05-2020_17-16/part-00000-607454d5-5b50-469e-98c3-1a895cf59c19-c000.snappy.parquet\noutput/15-05-2020_17-16/_SUCCESS\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}